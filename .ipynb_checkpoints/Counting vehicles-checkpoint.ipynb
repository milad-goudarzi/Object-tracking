{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1c07ea8",
   "metadata": {},
   "source": [
    "# Vehicle counting (YOLOv8 + ByteTrack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13900d34",
   "metadata": {},
   "source": [
    "<h3>Milad Goudarzi</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9766e267",
   "metadata": {},
   "source": [
    "<h4><b style=\"color:red\">Attention:</b> This is the procedure is carried out by me and you <span style=\"color:red\">do not</span> need to follow it. Just head to <a href=\"#simple_setup\">\"(Simply) set up the environment\"</a> step .<br/></h4>\n",
    "\n",
    "## <span style=\"font-size:13px\">(Hardly) </span>Set up the environment from scratch\n",
    "Install the package using below steps according to this link https://github.com/ifzhang/ByteTrack :<br/>\n",
    "### 1. Installing ByteTrack\n",
    "`git clone https://github.com/ifzhang/ByteTrack.git` <br/>\n",
    "`cd ByteTrack` <br/>\n",
    "`pip3 install -r requirements.txt` <br/>\n",
    "`python3 setup.py develop` <br/>\n",
    "### 2. Installing pycocotools\n",
    "Just run this command:\n",
    "`conda install -c conda-forge pycocotools`\n",
    "### 3. Installing cython_bbox\n",
    "We also need to install cython_bbox which cannot be installed using `pip` directly. We need to download the cython_bbox package from https://pypi.org/project/cython-bbox/ and then edit the setup.py:<br/>\n",
    "Open cython_bbox folder and find setup.py. Change line 31 in the setup.py from `extra_compile_args=['-Wno-cpp']`, to `extra_compile_args = {'gcc': ['/Qstd=c99']}`. After changing it, go to '.\\cython_bbox-0.1.3\\src' and edit the cython_bbox.pyx file. In cython_bbox.pyx line 12 change `DTYPE = np.float` to `DTYPE = np.float64`. After that, from the command line `cd` to the setup.py directory and run `pip install -e .` (include the dot) <br/>\n",
    "<hr/>\n",
    "\n",
    "### We also need to modify ByteTrack a little\n",
    "We need to change np.float to np.float64 in the following python scripts: \n",
    "<ul><li>jpnotebook\\bytetrack\\yolox\\tracker\\byte_tracker.py: line 18</li>\n",
    "<li>jpnotebook\\bytetrack\\yolox\\tracker\\matching.py (many cases, correct all of them) </li></ul>\n",
    "\n",
    "<h3> Note </h3> <br/>\n",
    "If you face the dead kernel issue due to libiomp5md.dll file in \"path_to_anaconda_envs\\your_env_name\\Library\\bin\\libiomp5md.dll\"\n",
    "directory, you can simply resolve it by deleting that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128529b5",
   "metadata": {},
   "source": [
    "<a id=\"simple_setup\"></a>\n",
    "## <span style=\"color:green\"> (Simply) Set up the environment</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7c25d4",
   "metadata": {},
   "source": [
    "0. You might need to update your Microsoft Visual C++ to version 14.0 or higher. But you might already have it. So just skip this step for now.\n",
    "1. Preferably install <a href=\"https://www.anaconda.com/download\"> anaconda </a> (or any other virtual environment platform).\n",
    "2. Open anaconda prompt and change your directory to the folder containing \"counting_vehicles.yml\" by `cd path\\to\\theFolder` and simply run this `conda env create -f counting_vehicles.yml`.\n",
    "3. Activate your virtual environment by running `conda activate object_tracking`.\n",
    "4. Open this notebook from the activated virtual environment.\n",
    "5. Run the cell below (ignore the dead kernel message afterwards as it is intentional):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62993fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd cython_bbox-0.1.3\n",
    "%pip install -e .\n",
    "%cd ..\n",
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bfa8e0",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<b style=\"color:green\"> 6. Done! </b><br/>\n",
    "<span style=\"color:red\">Note: </span> If you encountered with MS. Visual C++ error, you can use the `vs_BuildTools.exe` from project files to update to the required version (14 or higher). You need to install/update only the V.S. Build tools component."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1640be13",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c06d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\\ByteTrack\")\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import cv2\n",
    "from math import sqrt\n",
    "from yolox.tracker.byte_tracker import BYTETracker\n",
    "\n",
    "# YOLO with less parameters\n",
    "# model = YOLO(model='yolov8n.pt')\n",
    "\n",
    "# YOLO with large number of parameters\n",
    "model = YOLO('YOLOv8x.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df1c17d",
   "metadata": {},
   "source": [
    "# PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9774c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYTETrackerArgs:\n",
    "    def __init__(self, track_thresh, track_buffer, mot20, match_thresh, \\\n",
    "                aspect_ratio_thresh, min_box_area):\n",
    "        self.track_thresh        = track_thresh\n",
    "        self.track_buffer        = track_buffer\n",
    "        self.mot20               = mot20\n",
    "        self.match_thresh        = match_thresh\n",
    "        self.aspect_ratio_thresh = aspect_ratio_thresh\n",
    "        self.min_box_area        = min_box_area\n",
    "\n",
    "\n",
    "def countVehicles(video_path, output_file_name, vertical, roi_xxyy=(0,0,0,0)):\n",
    "    \n",
    "    assert type(video_path)       == str, \"video_path argument should be string\"\n",
    "    assert type(output_file_name) == str, \"output_file_name argument should be string\"\n",
    "    assert type(vertical)         == bool, \"vertical argument should be boolean\"\n",
    "    \n",
    "    args = BYTETrackerArgs(track_thresh = 0.25,\n",
    "                           track_buffer = 30,\n",
    "                           mot20 = False,\n",
    "                           match_thresh = 0.8,\n",
    "                           aspect_ratio_thresh = 3.0,\n",
    "                           min_box_area = 1.0)\n",
    "    \n",
    "    obj_tracker = BYTETracker(args)\n",
    "\n",
    "    vid     = cv2.VideoCapture(video_path) \n",
    "    counter = 0\n",
    "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "    writer= cv2.VideoWriter(str(output_file_name), cv2.VideoWriter_fourcc(*'DIVX'), fps, (1067,600))\n",
    "\n",
    "    ids                  = []\n",
    "    already_tested_ids   = []\n",
    "    too_close_tracks_ids = []\n",
    "    \n",
    "    maximum_n = 0 # to keep track of maximum height of counted vehicles in each row, so we can go to next row\n",
    "                  # when we reached end of the frame\n",
    "    while True:\n",
    "        ret, frame    = vid.read()\n",
    "\n",
    "        if ret:\n",
    "            frame         = cv2.resize(frame, (1067,600)) # maintaining 16:9 ratio\n",
    "            height, width = frame.shape[:2]\n",
    "            \n",
    "            # if cars are moving horizontally and user wants to use the default ROI parameters\n",
    "            if (not vertical) and roi_xxyy == (0,0,0,0):\n",
    "                x_starting_point = round(width/5)\n",
    "                x_ending_point   = round(4*width/5)\n",
    "                y_starting_point = round(height/2) + 50\n",
    "                y_ending_point   = round(height/2) + 250\n",
    "            \n",
    "            # if cars are moving vertically and user wants to use the default ROI parameters\n",
    "            elif (vertical) and roi_xxyy == (0,0,0,0):\n",
    "                x_starting_point = 0                #round(width/3)\n",
    "                x_ending_point   = round(3*width/4)\n",
    "                y_starting_point = round(height/2)\n",
    "                y_ending_point   = height           #round(height/2) + 100\n",
    "                \n",
    "            # if user wants to use the his own ROI parameters\n",
    "            else:\n",
    "                a, b, c, d = roi_xxyy\n",
    "                assert type(a) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(b) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(c) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                assert type(d) == int, \"roi_xxyy argument should be a list or tuple of integers\"\n",
    "                \n",
    "                x_starting_point = a\n",
    "                x_ending_point   = b\n",
    "                y_starting_point = c\n",
    "                y_ending_point   = d\n",
    "\n",
    "                \n",
    "            \n",
    "            if not vertical:\n",
    "                areaLine1   = x_starting_point + int((x_ending_point - x_starting_point)/2) - 15\n",
    "                areaLine2   = x_starting_point + int((x_ending_point - x_starting_point)/2) + 15\n",
    "            else:\n",
    "                areaLine1   = y_ending_point - 150\n",
    "                areaLine2   = y_ending_point - 100\n",
    "\n",
    "            # apply adaptive histogram equalization (AHE) in order to increase the contrast in our region of interest.\n",
    "            clahe = cv2.createCLAHE(clipLimit=4.0, tileGridSize=(8,8))\n",
    "\n",
    "            R, G, B = cv2.split(frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point]) # we don't need to\n",
    "                                                                                                         # apply AHE \n",
    "                                                                                                         # to the whole\n",
    "                                                                                                         # frame\n",
    "\n",
    "            cl1 = clahe.apply(R)\n",
    "            cl2 = clahe.apply(G)\n",
    "            cl3 = clahe.apply(B)\n",
    "\n",
    "            orig_frame       = frame.copy() # we take a copy of our original frame before loosing it.\n",
    "            frame            = cv2.merge((cl1, cl2, cl3))\n",
    "            frame_h, frame_w = frame.shape[:2]\n",
    "            frame_size       = np.array([frame_h, frame_w])\n",
    "            orig_frame[y_starting_point:y_ending_point, x_starting_point:x_ending_point] = frame # we replace the region of\n",
    "                                                                                                 # interest with\n",
    "                                                                                                 # the enhanced version of\n",
    "                                                                                                 # it.\n",
    "           \n",
    "            res    = model.predict(frame) # we do the prediction only on the ROI. and not the whole frame.\n",
    "    #         res    = model.predict(frame)\n",
    "            xyxys  = []\n",
    "            confss = []\n",
    "            oids   = []\n",
    "\n",
    "            for result in res:\n",
    "                for box, r in zip(result.boxes, result.boxes.data):\n",
    "                    x, y, w, h = box.xywh[0]\n",
    "                    # we add x_starting_point and y_starting_point to x and y coordinate because we shrinked the frame earlier\n",
    "                    x1, y1, x2, y2 = int(x) + x_starting_point - int(w/2), int(y) + y_starting_point - int(h/2),\\\n",
    "                                    int(x) + x_starting_point + int(w/2), int(y) + y_starting_point + int(h/2)           \n",
    "\n",
    "                    # if class of the detected object is not vehicle then discard it\n",
    "                    if r[-1] > 0 and r[-1] < 8:\n",
    "                        xyxys.append([x1, y1, x2, y2, r[-2]]) # xyxy and score\n",
    "                    confss.append(r[-2])\n",
    "                    oids.append(r[-1]) # class of the detected object\n",
    "\n",
    "\n",
    "            if len(xyxys) > 0:\n",
    "                tracks = obj_tracker.update(np.array(xyxys), frame_size, frame_size)\n",
    "            else:\n",
    "                tracks = np.array([])\n",
    "            if not vertical:\n",
    "                # areaLine1\n",
    "                cv2.line(orig_frame, (areaLine1, y_starting_point), (areaLine1,y_ending_point), (0,0,255), 2)\n",
    "                # areaLine2\n",
    "                cv2.line(orig_frame, (areaLine2, y_starting_point), (areaLine2,y_ending_point), (0,0,255), 2)\n",
    "            else:\n",
    "                # areaLine1\n",
    "                cv2.line(orig_frame, (x_starting_point, areaLine1), (x_ending_point,areaLine1), (0,0,255), 2)\n",
    "                # areaLine2\n",
    "                cv2.line(orig_frame, (x_starting_point, areaLine2), (x_ending_point,areaLine2), (0,0,255), 2)\n",
    "\n",
    "            for track in tracks:\n",
    "                \n",
    "                cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.5, [255, 255, 0], thickness=1, lineType=cv2.LINE_AA)\n",
    "                if not vertical:\n",
    "                    conditions = ((track.tlbr[0] > areaLine1 and track.tlbr[0]< areaLine2) and # upper left corner of the bbox should be in the area\n",
    "                                    track.track_id not in ids and\n",
    "                                    track.score > 0.6)\n",
    "                else:\n",
    "                    conditions = ((track.tlbr[1] > areaLine1 and track.tlbr[1]< areaLine2) and # upper left corner of the bbox should be in the area\n",
    "                                    track.track_id not in ids and\n",
    "                                    track.score > 0.6)\n",
    "\n",
    "                if (conditions):\n",
    "\n",
    "                    cv2.putText(orig_frame, str(track.track_id), (int(track.tlbr[0]), int(track.tlbr[1])),cv2.FONT_HERSHEY_SIMPLEX,0.8, [0, 255, 0], thickness=2, lineType=cv2.LINE_AA)                    \n",
    "                    ids.append(track.track_id)\n",
    "\n",
    "\n",
    "            # Showing the counter on top left side of the frame\n",
    "            counter = len(ids)\n",
    "            cv2.putText(orig_frame, \"Count: \" + str(counter), (50,50), fontFace = cv2.FONT_HERSHEY_SIMPLEX, fontScale = 1, color=(255, 0, 0))\n",
    "            \n",
    "            n = 20   # starting row for displaying the counted vehicle image in the original frame\n",
    "            m = 250  # starting column for displaying the counted vehicle image in the original frame\n",
    "            for track in tracks:\n",
    "                if (track.track_id in ids):\n",
    "                    cv2.rectangle(orig_frame, (int(track.tlbr[0]),int(track.tlbr[1])), (int(track.tlbr[2]),int(track.tlbr[3])), (0,255,0), 2)\n",
    "                    cv2.rectangle(orig_frame, (m, n), (m+int(track.tlwh[2]), n+int(track.tlwh[3])), (0,255,0), 2)\n",
    "                    try:\n",
    "                        orig_frame[n:n+int(track.tlwh[3]), m:m+int(track.tlwh[2])] = \\\n",
    "                            orig_frame[int(track.tlwh[1]):int(track.tlwh[1])+int(track.tlwh[3]), int(track.tlwh[0]):int(track.tlwh[0])+int(track.tlwh[2])]\n",
    "                        m += int(track.tlwh[2])+5\n",
    "                    except:\n",
    "                        print(\"Error!\")\n",
    "            \n",
    "            # drawing our RoI (Region of Interest)\n",
    "            cv2.rectangle(orig_frame, (x_starting_point, y_starting_point), (x_ending_point,y_ending_point), (255,255,0), 1)\n",
    "\n",
    "            writer.write(orig_frame)\n",
    "            cv2.imshow('frame', orig_frame)        \n",
    "\n",
    "            # press esc for quitting the video\n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    vid.release()\n",
    "    writer.release()\n",
    "    cv2.destroyAllWindows()            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options for videos: \n",
    "# vehicles moving vertically  (vertical: True): los_angeles.mp4, highway.mp4\n",
    "# vehicles moving horzintally (vertical: False): driving1.mp4\n",
    "countVehicles('los_angeles.mp4', 'test2.mp4', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0335e701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
